{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ILA_DkNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkFfaHmXHKUQ"
      },
      "source": [
        "# PyTorch Implementation of the paper 'Deep k-Nearest Neighbors'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NAXG9XqbyFP"
      },
      "source": [
        "                                                                                                                                                                                                                                                                                      This notebook contains a PyTorch implementation of the Deep k-Nearest Neighbors method introduced by Papernot & McDaniel (2018), which makes it possible to receive confidence scores for Deep Neural Network based predictions, that are more reliable than softmax scores. The paper can be found [here](https://arxiv.org/abs/1803.04765). The autors have also provided a basic implementation Tensorflow, which can be found [here](https://github.com/tensorflow/cleverhans/blob/master/cleverhans/model_zoo/deep_k_nearest_neighbors/dknn.py). However, this implementation is outdated. Hence, re-implemented the code here (in PyTorch)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTRgYdUwI_F6"
      },
      "source": [
        "First of all, a few package need to be installed. Besides Pytorch (pip packages torch and torchvision) we also need to install falconn and faiss. These two packages were used by Papernot and McDaniel to find the k-Nearest-Neighbors in high-dimensional spaces through local sensitive hashing (LSH). If you want to find our more about local sensitive hashing you can take a look [here](https://towardsdatascience.com/understanding-locality-sensitive-hashing-49f6d1f6134), [here](https://blog.mayflower.de/6498-lsh-nearest-neighbour-search.html), [here](https://www.youtube.com/watch?v=356GoYkmYKg&list=PLBv09BD7ez_6xoNh_luPdBmDCIHOQ3j7F) and [here](https://www.youtube.com/watch?v=gHdbqsDK9YY&list=PLBv09BD7ez_48heon5Az-TsyoXVYOJtDZ). However, I need to mention that falconn seems not to be under development anymore. Hence, someone might want to switch to another library providing local sensitive hashing in the future."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExlhM-ej9utH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2abdc4d-a1fc-4118-9ed1-3a88a0e45834"
      },
      "source": [
        "          ! apt-get install libomp-dev\n",
        "\n",
        "! pip uninstall torch torchvision -y\n",
        "! pip install torch==1.4.0 torchvision==0.5.0\n",
        "! pip install falconn==1.3.1\n",
        "! pip install faiss==1.5.3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libomp5\n",
            "Suggested packages:\n",
            "  libomp-doc\n",
            "The following NEW packages will be installed:\n",
            "  libomp-dev libomp5\n",
            "0 upgraded, 2 newly installed, 0 to remove and 34 not upgraded.\n",
            "Need to get 239 kB of archives.\n",
            "After this operation, 804 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp-dev amd64 5.0.1-1 [5,088 B]\n",
            "Fetched 239 kB in 2s (123 kB/s)\n",
            "Selecting previously unselected package libomp5:amd64.\n",
            "(Reading database ... 160690 files and directories currently installed.)\n",
            "Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp5:amd64 (5.0.1-1) ...\n",
            "Selecting previously unselected package libomp-dev.\n",
            "Preparing to unpack .../libomp-dev_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp-dev (5.0.1-1) ...\n",
            "Setting up libomp5:amd64 (5.0.1-1) ...\n",
            "Setting up libomp-dev (5.0.1-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Uninstalling torch-1.8.1+cu101:\n",
            "  Successfully uninstalled torch-1.8.1+cu101\n",
            "Uninstalling torchvision-0.9.1+cu101:\n",
            "  Successfully uninstalled torchvision-0.9.1+cu101\n",
            "Collecting torch==1.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/3b/fa92ece1e58a6a48ec598bab327f39d69808133e5b2fb33002ca754e381e/torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4MB 21kB/s \n",
            "\u001b[?25hCollecting torchvision==0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/32/cb0e4c43cd717da50258887b088471568990b5a749784c465a8a1962e021/torchvision-0.5.0-cp37-cp37m-manylinux1_x86_64.whl (4.0MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0MB 37.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.5.0) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.5.0) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchvision==0.5.0) (1.15.0)\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.4.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, torchvision\n",
            "Successfully installed torch-1.4.0 torchvision-0.5.0\n",
            "Collecting falconn==1.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/b8/0d2c629d59398a7b3ed8726ce049abf6746bbf09d1ad15878d4fcf8048a6/FALCONN-1.3.1.tar.gz (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 4.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: falconn\n",
            "  Building wheel for falconn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for falconn: filename=FALCONN-1.3.1-cp37-cp37m-linux_x86_64.whl size=10582799 sha256=92a8f31cd3b664f71b33827a873e3598e26419b6514bf2dde413d964d6433fa2\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/36/96/d5538901888620fc0343c1ed9d5f87fce00869e00c12056ef8\n",
            "Successfully built falconn\n",
            "Installing collected packages: falconn\n",
            "Successfully installed falconn-1.3.1\n",
            "Collecting faiss==1.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ef/2e/dc5697e9ff6f313dcaf3afe5ca39d7d8334114cbabaed069d0026bbc3c61/faiss-1.5.3-cp37-cp37m-manylinux1_x86_64.whl (4.7MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7MB 4.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from faiss==1.5.3) (1.19.5)\n",
            "Installing collected packages: faiss\n",
            "Successfully installed faiss-1.5.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "QnjEeHFeGmLW",
        "outputId": "8582fe4a-6843-412a-ce23-6248da057f8d"
      },
      "source": [
        "!pip install numpy==1.16.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.16.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/57/07c49e1a6d2706fb7336b3fb11dd285c1e96535c80833d7524f002f57086/numpy-1.16.1-cp37-cp37m-manylinux1_x86_64.whl (17.3MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3MB 189kB/s \n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement numpy~=1.19.2, but you'll have numpy 1.16.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pyarrow 3.0.0 has requirement numpy>=1.16.6, but you'll have numpy 1.16.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: astropy 4.2.1 has requirement numpy>=1.17, but you'll have numpy 1.16.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "Successfully installed numpy-1.16.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynRTCtFTGjxo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "b963743a-a255-4a08-ca54-15685b6c9e38"
      },
      "source": [
        "\n",
        "%%capture --no-stderr --no-display\n",
        "# NBVAL_IGNORE_OUTPUT\n",
        "\n",
        "try:\n",
        "  import secml\n",
        "except ImportError:\n",
        "  %pip install git+https://gitlab.com/secml/secml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VW20mnSsLAEI"
      },
      "source": [
        "Next, let's load the required modules from the packages. Furthermore, for reproducibility reasons I also like to print out the package version that are used here and some GPU information if a GPU is available (since I only do the testing using MNIST a CPU should work here as well)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PTvaJ7Q9yo8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8010d5c9-6f13-4a5a-b575-e331b7e9dab5"
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import numpy as np\n",
        "import falconn\n",
        "import faiss\n",
        "import platform\n",
        "import enum\n",
        "import copy\n",
        "from bisect import bisect_left\n",
        "import warnings\n",
        "\n",
        "print('python version:      {}'.format(platform.python_version()))\n",
        "print('torch version:       {}'.format(torch.__version__))\n",
        "print('torchvision version: {}'.format(torchvision.__version__))\n",
        "print('numpy version:       {}'.format(np.__version__))\n",
        "print('matplotlib version:  {}'.format(matplotlib.__version__))\n",
        "print('pickle version:      {}'.format(pickle.format_version))\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "print('CUDA available:      {}'.format(use_cuda))\n",
        "print('cuDNN enabled:       {}'.format(torch.backends.cudnn.enabled))\n",
        "print('num gpus:            {}'.format(torch.cuda.device_count()))\n",
        "\n",
        "if use_cuda:\n",
        "    print('gpu:                 {}'.format(torch.cuda.get_device_name(0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python version:      3.7.10\n",
            "torch version:       1.4.0\n",
            "torchvision version: 0.5.0\n",
            "numpy version:       1.19.5\n",
            "matplotlib version:  3.2.2\n",
            "pickle version:      4.0\n",
            "CUDA available:      True\n",
            "cuDNN enabled:       True\n",
            "num gpus:            1\n",
            "gpu:                 Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yb63e9GR-Aii"
      },
      "source": [
        "Put CUDNN to deterministic and set seed values for [reproducibility reasons](https://pytorch.org/docs/stable/notes/randomness.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMH4t0VK9-Cp"
      },
      "source": [
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "random_seed = 0\n",
        "torch.manual_seed(random_seed)\n",
        "np.random.seed(random_seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELNzocTU-DwE"
      },
      "source": [
        "Let's set some parameters for the Deep kNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dBVyKcX4qNw"
      },
      "source": [
        "num_epochs = 10            # number of training epochs\n",
        "batch_size_train = 50    # batch size for training\n",
        "batch_size_test = 50    # batch size for testing\n",
        "learning_rate = 0.001     # learning rate for training\n",
        "calibset_size = 50       # size of the calibration set for DkNN\n",
        "neighbors = 75            # number of nearest neighbors for DkNN\n",
        "number_bits = 17          # number of bits for LSH for DkNN\n",
        "\n",
        "log_interval = 10         # printing training statistics after 10 iterations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wik1VDmc-GfA"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7c2zcL7yVUC"
      },
      "source": [
        "### Specify Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoGsnIwryaom"
      },
      "source": [
        "Define data transform functions for training and test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmUEEiqvyRj4"
      },
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQKJcyi_yfkV"
      },
      "source": [
        "Define training and test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab3XXMh5WVIp"
      },
      "source": [
        "train_x = np.load('clean_poisoned_X.npy')\n",
        "train_y = np.load('clean_poisoned_Y.npy')\n",
        "\n",
        "calib_x = np.load('calib_x.npy')\n",
        "calib_y = np.load('calib_y.npy')\n",
        "\n",
        "test_x = np.load('test_x.npy')\n",
        "test_y = np.load('test_y.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkzTAGrVYOPb"
      },
      "source": [
        "def get_tensor_data(x,Y):\n",
        "  c_data = torch.Tensor(x.reshape(-1,1,28,28))\n",
        "  c_label = torch.Tensor(Y).long()\n",
        "  dataset = TensorDataset(c_data,c_label)\n",
        "  return dataset\n",
        "# trainset = torch.utils.data.DataLoader(ds, batch_size=50, shuffle=False, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzkfsKPQaVXo"
      },
      "source": [
        "trainset = get_tensor_data(train_x,train_y)\n",
        "calibset = get_tensor_data(calib_x,calib_y)\n",
        "testset = get_tensor_data(test_x,test_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeakmI6Xyf8-"
      },
      "source": [
        "# # Training set\n",
        "# trainset = torchvision.datasets.MNIST(\n",
        "#     root='./data', train=True, download=True, transform=transform\n",
        "# )\n",
        "\n",
        "# # Test set and calibration set\n",
        "# orig_testset = torchvision.datasets.MNIST(\n",
        "#     root='./data', train=False, download=True, transform=transform\n",
        "# )\n",
        "# orig_testset_size = len(orig_testset)\n",
        "\n",
        "# testset_size = orig_testset_size - calibset_size\n",
        "# testset, calibset = torch.utils.data.random_split(orig_testset, [testset_size, calibset_size])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyI4WzgGSJHx"
      },
      "source": [
        "Add poisoned data to the MNIST Train Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOlzvs2Tb6ch"
      },
      "source": [
        "# poisoned_data = np.load('poisoned_data_X.npy')\n",
        "# poisoned_data_label = np.load('poisoned_data_Y.npy')\n",
        "\n",
        "# poisoned_data_x = torch.Tensor(poisoned_data.reshape(len(poisoned_data),28,28)).byte()\n",
        "# poisoned_data_y = torch.Tensor(poisoned_data_label).long()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbi4Zeofct6q"
      },
      "source": [
        "# trainset.data = torch.cat((trainset.data,poisoned_data_x),dim=0)\n",
        "# trainset.targets = torch.cat((trainset.targets,poisoned_data_y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzgtNQAwymuT"
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlSfVhWEyxG7"
      },
      "source": [
        "Create train, test and calibration data loader."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fi0GzKryxw4"
      },
      "source": [
        "# Create training data loader\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=batch_size_train, shuffle=True, num_workers=2\n",
        ")\n",
        "\n",
        "# Create test data loader\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=batch_size_test, shuffle=False, num_workers=2\n",
        ")\n",
        "\n",
        "# Create calib data loader\n",
        "calibloader = torch.utils.data.DataLoader(\n",
        "    calibset, batch_size=calibset_size, shuffle=False, num_workers=2\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3RYPPe4TDwQ",
        "outputId": "b20f831e-ef00-45bd-d427-4054eb7132a1"
      },
      "source": [
        "trainset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataset.TensorDataset at 0x7fd8c8f4cb90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ha-pQCWXb0Iv"
      },
      "source": [
        "Print out the sizes of the datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5XTyUe0b31Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "106d97de-69c0-477a-94c2-41ea44ba6fe5"
      },
      "source": [
        "print('trainset size: {}'.format(len(trainloader.dataset)))\n",
        "print('testset size:  {}'.format(len(testloader.dataset)))\n",
        "print('calibset size: {}'.format(len(calibloader.dataset)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trainset size: 1050\n",
            "testset size:  500\n",
            "calibset size: 500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvhyHSj_y2Ra"
      },
      "source": [
        "### Display Samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQBLPagqy2_J"
      },
      "source": [
        "def show_samples(data, targets):\n",
        "    data = data.numpy()\n",
        "    print(\"tensor shape: \" + str(data.shape))\n",
        "    \n",
        "    fig = plt.figure()\n",
        "    for i in range(9):\n",
        "        plt.subplot(3,3,i+1)\n",
        "        plt.tight_layout()\n",
        "        \n",
        "        img = data * 0.3081 + 0.1307  # unnormalize\n",
        "        plt.imshow(img[i][0], cmap='gray', interpolation='none')\n",
        "        plt.title(\"Ground Truth: {}\".format(targets[i]))\n",
        "        \n",
        "        plt.xticks([])\n",
        "        plt.yticks([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kXdGSzry8Ce"
      },
      "source": [
        "Load a few test images and display them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woBy6gE-y8YR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "75411a3f-e67f-4d9f-faa6-5042514f2f02"
      },
      "source": [
        "dataiter = enumerate(testloader)\n",
        "_, (sample_data, sample_targets) = next(dataiter)\n",
        "\n",
        "show_samples(sample_data, sample_targets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor shape: (50, 1, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nrEJtUA4vwY"
      },
      "source": [
        "## Define Training and Test Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqpIuwp2awI9"
      },
      "source": [
        "Let's define the functions for training and testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgBe_-yy4w-B"
      },
      "source": [
        "def train(num_epochs, model, optim, crit, train_loader, test_loader):\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    test_accs = []\n",
        "    \n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        model, train_losses = train_one_epoch(epoch, model, optim, crit, train_loader, train_losses)\n",
        "        test_losses, test_accs,_,_ = test(model, crit, test_loader, test_losses, test_accs)\n",
        "        \n",
        "    print('Finished Training')\n",
        "    return train_losses, test_losses, test_accs\n",
        "    \n",
        "\n",
        "def train_one_epoch(epoch_num, model, optim, crit, data_loader, losses):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    for batch_idx, data in enumerate(data_loader):\n",
        "        # Get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, targets = data\n",
        "\n",
        "        if use_cuda:\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "        \n",
        "        # Zero the parameter gradients\n",
        "        optim.zero_grad()\n",
        "        \n",
        "        # Forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = crit(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Print statistics\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        if batch_idx % log_interval == 0:\n",
        "            dataset_size = len(data_loader.dataset)\n",
        "            used_samples = batch_idx * len(inputs)\n",
        "            train_progress = 100. * batch_idx / len(data_loader)\n",
        "            avg_batch_loss = running_loss / log_interval\n",
        "            \n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch_num, used_samples, dataset_size, train_progress, avg_batch_loss\n",
        "            ))\n",
        "            \n",
        "            losses.append(avg_batch_loss)\n",
        "            running_loss = 0.0\n",
        "            \n",
        "    return model, losses\n",
        "     \n",
        "    \n",
        "def test(model, crit, data_loader, test_losses, test_accs):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    test_loss = 0\n",
        "    pred_labels = []\n",
        "    true_labels = []\n",
        "    with torch.no_grad():\n",
        "        for data in data_loader:\n",
        "            # Get the inputs; data is a list of [inputs, labels]\n",
        "            inputs, targets = data\n",
        "\n",
        "            if use_cuda:\n",
        "              inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            \n",
        "            # Forward + loss + correct\n",
        "            outputs = model(inputs)\n",
        "            test_loss += crit(outputs, targets).item()\n",
        "            \n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "            # print('labels:',predicted.cpu().numpy().astype('int32').shape)\n",
        "\n",
        "            pred_labels += list(predicted.cpu().numpy().astype('int32').flatten())\n",
        "            true_labels += list(targets.cpu().numpy().astype('int32').flatten())\n",
        "\n",
        "    dataset_size = len(data_loader.dataset)\n",
        "    test_loss /= dataset_size\n",
        "    acc = 100. * correct / dataset_size\n",
        "    \n",
        "    test_losses.append(test_loss)\n",
        "    test_accs.append(acc)\n",
        "    \n",
        "    print('\\nTest set: Avg. loss: {:.6f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, dataset_size, acc\n",
        "    ))\n",
        "    \n",
        "    return test_losses,test_accs,pred_labels,true_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YFZQkAi450A"
      },
      "source": [
        "## Network Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52b1IG-ra3eH"
      },
      "source": [
        "Let's define the neural network based model architecture for MNIST, that has also been [used by Papernot and McDaniel](https://github.com/tensorflow/cleverhans/blob/master/cleverhans/model_zoo/deep_k_nearest_neighbors/dknn.py)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7Pt-A4Z47aj"
      },
      "source": [
        "class MnistNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MnistNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=8, stride=2, padding=3)\n",
        "        self.relu1 = nn.ReLU(True)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=6, stride=2)\n",
        "        self.relu2 = nn.ReLU(True)\n",
        "        self.conv3 = nn.Conv2d(128, 128, kernel_size=5)\n",
        "        self.relu3 = nn.ReLU(True)\n",
        "        self.fc = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu1(self.conv1(x))\n",
        "        x = self.relu2(self.conv2(x))\n",
        "        x = self.relu3(self.conv3(x))\n",
        "        x = x.view(-1, 128)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szo94UrQH0qc"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXs2dnBFISBR"
      },
      "source": [
        "Let's train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rP4BTofQITUI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd182eee-e67e-4a46-c35b-50981ea4d173"
      },
      "source": [
        "# Create Model\n",
        "model = MnistNet()\n",
        "\n",
        "if use_cuda:\n",
        "    model.cuda()\n",
        "    print('Using ', torch.cuda.device_count(), ' GPU(s)')\n",
        "\n",
        "# Define Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Start Training\n",
        "_, _, accs = train(num_epochs, model, optimizer, criterion, trainloader, testloader)\n",
        "\n",
        "print()\n",
        "print('Accuracies: {}'.format(accs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using  1  GPU(s)\n",
            "Train Epoch: 1 [0/1050 (0%)]\tLoss: 0.228818\n",
            "Train Epoch: 1 [500/1050 (48%)]\tLoss: 0.692764\n",
            "Train Epoch: 1 [1000/1050 (95%)]\tLoss: 0.407434\n",
            "\n",
            "Test set: Avg. loss: 0.004305, Accuracy: 457/500 (91.40%)\n",
            "\n",
            "Train Epoch: 2 [0/1050 (0%)]\tLoss: 0.041239\n",
            "Train Epoch: 2 [500/1050 (48%)]\tLoss: 0.245698\n",
            "Train Epoch: 2 [1000/1050 (95%)]\tLoss: 0.241911\n",
            "\n",
            "Test set: Avg. loss: 0.002257, Accuracy: 491/500 (98.20%)\n",
            "\n",
            "Train Epoch: 3 [0/1050 (0%)]\tLoss: 0.025021\n",
            "Train Epoch: 3 [500/1050 (48%)]\tLoss: 0.250420\n",
            "Train Epoch: 3 [1000/1050 (95%)]\tLoss: 0.174357\n",
            "\n",
            "Test set: Avg. loss: 0.001121, Accuracy: 495/500 (99.00%)\n",
            "\n",
            "Train Epoch: 4 [0/1050 (0%)]\tLoss: 0.008627\n",
            "Train Epoch: 4 [500/1050 (48%)]\tLoss: 0.228799\n",
            "Train Epoch: 4 [1000/1050 (95%)]\tLoss: 0.196873\n",
            "\n",
            "Test set: Avg. loss: 0.001290, Accuracy: 493/500 (98.60%)\n",
            "\n",
            "Train Epoch: 5 [0/1050 (0%)]\tLoss: 0.023115\n",
            "Train Epoch: 5 [500/1050 (48%)]\tLoss: 0.210300\n",
            "Train Epoch: 5 [1000/1050 (95%)]\tLoss: 0.186538\n",
            "\n",
            "Test set: Avg. loss: 0.001391, Accuracy: 494/500 (98.80%)\n",
            "\n",
            "Train Epoch: 6 [0/1050 (0%)]\tLoss: 0.006968\n",
            "Train Epoch: 6 [500/1050 (48%)]\tLoss: 0.195911\n",
            "Train Epoch: 6 [1000/1050 (95%)]\tLoss: 0.196000\n",
            "\n",
            "Test set: Avg. loss: 0.001238, Accuracy: 495/500 (99.00%)\n",
            "\n",
            "Train Epoch: 7 [0/1050 (0%)]\tLoss: 0.012439\n",
            "Train Epoch: 7 [500/1050 (48%)]\tLoss: 0.217581\n",
            "Train Epoch: 7 [1000/1050 (95%)]\tLoss: 0.159008\n",
            "\n",
            "Test set: Avg. loss: 0.001186, Accuracy: 496/500 (99.20%)\n",
            "\n",
            "Train Epoch: 8 [0/1050 (0%)]\tLoss: 0.013125\n",
            "Train Epoch: 8 [500/1050 (48%)]\tLoss: 0.150684\n",
            "Train Epoch: 8 [1000/1050 (95%)]\tLoss: 0.218556\n",
            "\n",
            "Test set: Avg. loss: 0.001634, Accuracy: 495/500 (99.00%)\n",
            "\n",
            "Train Epoch: 9 [0/1050 (0%)]\tLoss: 0.016217\n",
            "Train Epoch: 9 [500/1050 (48%)]\tLoss: 0.172038\n",
            "Train Epoch: 9 [1000/1050 (95%)]\tLoss: 0.187591\n",
            "\n",
            "Test set: Avg. loss: 0.001281, Accuracy: 495/500 (99.00%)\n",
            "\n",
            "Train Epoch: 10 [0/1050 (0%)]\tLoss: 0.009267\n",
            "Train Epoch: 10 [500/1050 (48%)]\tLoss: 0.160832\n",
            "Train Epoch: 10 [1000/1050 (95%)]\tLoss: 0.176259\n",
            "\n",
            "Test set: Avg. loss: 0.001507, Accuracy: 495/500 (99.00%)\n",
            "\n",
            "Finished Training\n",
            "\n",
            "Accuracies: [91.4, 98.2, 99.0, 98.6, 98.8, 99.0, 99.2, 99.0, 99.0, 99.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOX5Iwrde9f5"
      },
      "source": [
        "Put model in evaluation mode."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zp87Rx-ed-FV",
        "outputId": "68e9c6a7-910c-4cd9-9b19-7f4ffc249879"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MnistNet(\n",
              "  (conv1): Conv2d(1, 64, kernel_size=(8, 8), stride=(2, 2), padding=(3, 3))\n",
              "  (relu1): ReLU(inplace=True)\n",
              "  (conv2): Conv2d(64, 128, kernel_size=(6, 6), stride=(2, 2))\n",
              "  (relu2): ReLU(inplace=True)\n",
              "  (conv3): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (relu3): ReLU(inplace=True)\n",
              "  (fc): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g10p0O_9fAOe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b67eea50-3fa6-49ff-a079-5487981d5f1a"
      },
      "source": [
        "model.eval()\n",
        "\n",
        "if use_cuda:\n",
        "    model.cuda()\n",
        "    print('Using ', torch.cuda.device_count(), ' GPU(s)')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using  1  GPU(s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRreifcIgVNz"
      },
      "source": [
        "Let's test our model again to see again which accuracy we have finally reached."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GblopwOcg1HF"
      },
      "source": [
        "def test_final(model, data_loader):\n",
        "    _, accs,_ ,_= test(model, criterion, data_loader, [], [])\n",
        "    return accs[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4Fzf1exv77X"
      },
      "source": [
        "Get the labels from DNN for the training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dq7Jj3W3hdbv",
        "outputId": "e58fc9a6-e32a-43a2-f259-2a9353c628e6"
      },
      "source": [
        "trainset.tensors[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1050, 1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnMMrstut_ul"
      },
      "source": [
        "# res = model(trainset.tensors[0].cuda().float())\n",
        "# #trainset.data.cuda().float().reshape(-1,1,28,28)\n",
        "# pred_label = np.argmax(res.cpu().detach().numpy(),axis=1)\n",
        "# pred_label.shape\n",
        "# train_labels = trainset.tensors[1].numpy()\n",
        "# train_labels.shape\n",
        "# Get the misclassified training points\n",
        "# misclassified_train_idx = np.where(pred_label!=train_labels)[0]\n",
        "# print('acc:',1-len(misclassified_train_idx)/len(train_labels))\n",
        "# misclassified_train_data = trainset.tensors[0].numpy()[misclassified_train_idx]\n",
        "# misclassified_train_label = trainset.tensors[0].numpy()[misclassified_train_idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOw1TsTvisjv"
      },
      "source": [
        "## Get Activations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x0SMfDRuQdQ"
      },
      "source": [
        "Now, let's try to get the activations of each layer when feeding the trained model with images. To see again which layers we have let's print the model architecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tY8QtZHlgxVt",
        "outputId": "0b38e9d9-4aab-43a7-a796-3f96f6abbb3f"
      },
      "source": [
        "result = test(model,criterion,trainloader,[],[])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg. loss: 0.003050, Accuracy: 1000/1050 (95.24%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aw3jUxkguTeV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2fb94f8-f62b-4d5a-aea9-9f81c2d4b8c1"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MnistNet(\n",
              "  (conv1): Conv2d(1, 64, kernel_size=(8, 8), stride=(2, 2), padding=(3, 3))\n",
              "  (relu1): ReLU(inplace=True)\n",
              "  (conv2): Conv2d(64, 128, kernel_size=(6, 6), stride=(2, 2))\n",
              "  (relu2): ReLU(inplace=True)\n",
              "  (conv3): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (relu3): ReLU(inplace=True)\n",
              "  (fc): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-395Iz3PuYiA"
      },
      "source": [
        "Specify layers to be used for the DkNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rnlpkyntj0tf"
      },
      "source": [
        "layers = {\n",
        "    'relu1': model.relu1,\n",
        "    'relu2': model.relu2,\n",
        "    'relu3': model.relu3,\n",
        "    'fc': model.fc\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ar9rmLtluyZj"
      },
      "source": [
        "Define function to get activations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-d9ohncXP0gw"
      },
      "source": [
        "def get_activations(dataloader, model, layers):\n",
        "    activations = {}\n",
        "    activations['activations'] = {}\n",
        "    activations['targets'] = None\n",
        "\n",
        "    for layer_name in layers:\n",
        "        print('## Fetching Activations from Layer {}'.format(layer_name))\n",
        "\n",
        "        # Get activations for the data\n",
        "        layer = layers[layer_name]\n",
        "        activations['activations'][layer_name], targets = get_activations_from_layer(dataloader, model, layer)\n",
        "\n",
        "        # Get the targets of that data\n",
        "        if targets is not None:\n",
        "            if activations['targets'] is not None:\n",
        "                np.testing.assert_array_equal(activations['targets'], targets)\n",
        "            else:\n",
        "                activations['targets'] = targets\n",
        "\n",
        "        print()\n",
        "\n",
        "    return activations\n",
        "\n",
        "def get_activations_from_layer(dataloader, model, layer):\n",
        "    activations = []\n",
        "    targets = []\n",
        "\n",
        "    # Define hook for fetching the activations\n",
        "    def hook(module, input, output):\n",
        "        layer_activations = output.squeeze().detach().cpu().numpy()\n",
        "\n",
        "        if len(layer_activations.shape) == 4:\n",
        "            layer_activations = layer_activations.reshape(layer_activations.shape[0], -1)\n",
        "        \n",
        "        activations.append(layer_activations)\n",
        "\n",
        "    handle = layer.register_forward_hook(hook)\n",
        "\n",
        "    # Fetch activations\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        print('Processing Batch {}'.format(i))\n",
        "        \n",
        "\n",
        "        if use_cuda:\n",
        "            batch = [_batch.cuda() for _batch in batch]\n",
        "            #batch = batch.cuda()\n",
        "            \n",
        "\n",
        "        _ = model(batch[0])\n",
        "\n",
        "        if len(batch) > 1:\n",
        "          targets.append(batch[1].detach().cpu().numpy())\n",
        "\n",
        "    print(\"done!\")\n",
        "\n",
        "    # Remove hook\n",
        "    handle.remove()\n",
        "\n",
        "    # Return activations and targets\n",
        "    activations = np.concatenate(activations)\n",
        "\n",
        "    if targets:\n",
        "        targets = np.hstack(targets)\n",
        "    else:\n",
        "        None\n",
        "\n",
        "    return activations, targets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zC9ivurMgBl0"
      },
      "source": [
        "Test activation fetching."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wqOGH2BgD3j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a9bc1ac-4081-45d8-f87e-71d14fd87dfa"
      },
      "source": [
        "acts = get_activations(calibloader, model, layers)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "## Fetching Activations from Layer relu1\n",
            "Processing Batch 0\n",
            "Processing Batch 1\n",
            "Processing Batch 2\n",
            "Processing Batch 3\n",
            "Processing Batch 4\n",
            "Processing Batch 5\n",
            "Processing Batch 6\n",
            "Processing Batch 7\n",
            "Processing Batch 8\n",
            "Processing Batch 9\n",
            "done!\n",
            "\n",
            "## Fetching Activations from Layer relu2\n",
            "Processing Batch 0\n",
            "Processing Batch 1\n",
            "Processing Batch 2\n",
            "Processing Batch 3\n",
            "Processing Batch 4\n",
            "Processing Batch 5\n",
            "Processing Batch 6\n",
            "Processing Batch 7\n",
            "Processing Batch 8\n",
            "Processing Batch 9\n",
            "done!\n",
            "\n",
            "## Fetching Activations from Layer relu3\n",
            "Processing Batch 0\n",
            "Processing Batch 1\n",
            "Processing Batch 2\n",
            "Processing Batch 3\n",
            "Processing Batch 4\n",
            "Processing Batch 5\n",
            "Processing Batch 6\n",
            "Processing Batch 7\n",
            "Processing Batch 8\n",
            "Processing Batch 9\n",
            "done!\n",
            "\n",
            "## Fetching Activations from Layer fc\n",
            "Processing Batch 0\n",
            "Processing Batch 1\n",
            "Processing Batch 2\n",
            "Processing Batch 3\n",
            "Processing Batch 4\n",
            "Processing Batch 5\n",
            "Processing Batch 6\n",
            "Processing Batch 7\n",
            "Processing Batch 8\n",
            "Processing Batch 9\n",
            "done!\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ra7WMB7j016",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84605051-0aac-4f3e-a9ef-53ed001f4de2"
      },
      "source": [
        "print('targets: {}'.format(acts['targets'].shape))\n",
        "print()\n",
        "\n",
        "for layer in layers:\n",
        "    print('## layer {}'.format(layer))\n",
        "    print('activations: {}'.format(acts['activations'][layer].shape))\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "targets: (500,)\n",
            "\n",
            "## layer relu1\n",
            "activations: (500, 12544)\n",
            "\n",
            "## layer relu2\n",
            "activations: (500, 3200)\n",
            "\n",
            "## layer relu3\n",
            "activations: (500, 128)\n",
            "\n",
            "## layer fc\n",
            "activations: (500, 10)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRNHTEVitJmU"
      },
      "source": [
        "# Deep kNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBSJ_lc6w0II"
      },
      "source": [
        "Now, let's implement DkNN. The code is based on the original [code from Papernot and McDaniel](https://github.com/tensorflow/cleverhans/blob/master/cleverhans/model_zoo/deep_k_nearest_neighbors/dknn.py). It was converted to PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-s3P0R-KkTq8"
      },
      "source": [
        "class NearestNeighbor:\n",
        "\n",
        "    class BACKEND(enum.Enum):\n",
        "        FALCONN = 1\n",
        "        FAISS = 2\n",
        "\n",
        "    def __init__(self, backend, dimension, neighbors, number_bits, nb_tables=None):\n",
        "        assert backend in NearestNeighbor.BACKEND\n",
        "\n",
        "        self._NEIGHBORS = neighbors\n",
        "        self._BACKEND = backend\n",
        "\n",
        "        if self._BACKEND is NearestNeighbor.BACKEND.FALCONN:\n",
        "            self._init_falconn(dimension, number_bits, nb_tables)\n",
        "        elif self._BACKEND is NearestNeighbor.BACKEND.FAISS:\n",
        "            self._init_faiss(dimension)\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "    def _init_falconn(self, dimension, number_bits, nb_tables):\n",
        "        assert nb_tables >= self._NEIGHBORS\n",
        "\n",
        "        # LSH parameters\n",
        "        params_cp = falconn.LSHConstructionParameters()\n",
        "        params_cp.dimension = dimension\n",
        "        params_cp.lsh_family = falconn.LSHFamily.CrossPolytope\n",
        "        params_cp.distance_function = falconn.DistanceFunction.EuclideanSquared\n",
        "        params_cp.l = nb_tables\n",
        "        params_cp.num_rotations = 2  # for dense set it to 1; for sparse data set it to 2\n",
        "        params_cp.seed = 5721840\n",
        "        params_cp.num_setup_threads = 0  # we want to use all the available threads to set up\n",
        "        params_cp.storage_hash_table = falconn.StorageHashTable.BitPackedFlatHashTable\n",
        "\n",
        "        # we build number_bits-bit hashes so that each table has\n",
        "        # 2^number_bits bins; a rule of thumb is to have the number\n",
        "        # of bins be the same order of magnitude as the number of data points\n",
        "        falconn.compute_number_of_hash_functions(number_bits, params_cp)\n",
        "        self._falconn_table = falconn.LSHIndex(params_cp)\n",
        "        self._falconn_query_object = None\n",
        "        self._FALCONN_NB_TABLES = nb_tables\n",
        "\n",
        "    def _init_faiss(self, dimension):\n",
        "        res = faiss.StandardGpuResources()\n",
        "        self._faiss_index = faiss.GpuIndexFlatL2(res, dimension)\n",
        "\n",
        "    def add(self, x):\n",
        "        if self._BACKEND is NearestNeighbor.BACKEND.FALCONN:\n",
        "            self._falconn_table.setup(x)\n",
        "        elif self._BACKEND is NearestNeighbor.BACKEND.FAISS:\n",
        "            self._faiss_index.add(x)\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "    def find_knns(self, x, output):\n",
        "        if self._BACKEND is NearestNeighbor.BACKEND.FALCONN:\n",
        "            return self._find_knns_falconn(x, output)\n",
        "        elif self._BACKEND is NearestNeighbor.BACKEND.FAISS:\n",
        "            return self._find_knns_faiss(x, output)\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "    def _find_knns_falconn(self, x, output):\n",
        "        # Late falconn query_object construction\n",
        "        # Since I suppose there might be an error\n",
        "        # if table.setup() will be called after\n",
        "        if self._falconn_query_object is None:\n",
        "            self._falconn_query_object = self._falconn_table.construct_query_object()\n",
        "            self._falconn_query_object.set_num_probes(self._FALCONN_NB_TABLES)\n",
        "\n",
        "        missing_indices = np.zeros(output.shape, dtype=np.bool)\n",
        "\n",
        "        for i in range(x.shape[0]):\n",
        "            query_res = self._falconn_query_object.find_k_nearest_neighbors(x[i], self._NEIGHBORS)\n",
        "\n",
        "            try:\n",
        "                output[i, :] = query_res\n",
        "            except:\n",
        "                # mark missing indices\n",
        "                missing_indices[i, len(query_res):] = True\n",
        "                output[i, :len(query_res)] = query_res\n",
        "\n",
        "        return missing_indices\n",
        "\n",
        "    def _find_knns_faiss(self, x, output):\n",
        "        neighbor_distance, neighbor_index = self._faiss_index.search(x, self._NEIGHBORS)\n",
        "\n",
        "        missing_indices = neighbor_distance == -1\n",
        "        d1 = neighbor_index.reshape(-1)\n",
        "\n",
        "        output.reshape(-1)[np.logical_not(missing_indices.flatten())] = d1[np.logical_not(missing_indices.flatten())]\n",
        "\n",
        "        return missing_indices\n",
        "\n",
        "\n",
        "class DkNN:\n",
        "\n",
        "    def __init__(self, model, nb_classes, neighbors, layers, trainloader, nearest_neighbor_backend, nb_tables=200, number_bits=17):\n",
        "        \"\"\"\n",
        "        Implementation of the DkNN algorithm, see https://arxiv.org/abs/1803.04765 for more details\n",
        "        :param model: model to be used\n",
        "        :param nb_classes: the number of classes in the task\n",
        "        :param neighbors: number of neighbors to find per layer\n",
        "        :param layers: a list of layer names to include in the DkNN\n",
        "        :param trainloader: data loader for the training data\n",
        "        :param nearest_neighbor_backend: falconn or faiss to be used for LSH\n",
        "        :param nb_tables: number of tables used by FALCONN to perform locality-sensitive hashing.\n",
        "        :param number_bits: number of hash bits used by LSH.\n",
        "        \"\"\"\n",
        "        print('---------- DkNN init')\n",
        "        print()\n",
        "\n",
        "        self.model = model\n",
        "        self.nb_classes = nb_classes\n",
        "        self.neighbors = neighbors\n",
        "        self.layers = layers\n",
        "        self.backend = nearest_neighbor_backend\n",
        "        self.nb_tables = nb_tables\n",
        "        self.number_bits = number_bits\n",
        "\n",
        "        self.nb_cali = -1\n",
        "        self.calibrated = False   \n",
        "\n",
        "        # Compute training data activations\n",
        "        activations = get_activations(trainloader, model, layers)\n",
        "        self.train_activations = activations['activations']\n",
        "        self.train_labels = activations['targets']\n",
        "\n",
        "        # Build locality-sensitive hashing tables for training representations\n",
        "        self.train_activations_lsh = copy.copy(self.train_activations)\n",
        "        self.init_lsh()\n",
        "\n",
        "    def init_lsh(self):\n",
        "        \"\"\"\n",
        "        Initializes locality-sensitive hashing with FALCONN to find nearest neighbors in training data\n",
        "        \"\"\"\n",
        "        self.query_objects = {} # contains the object that can be queried to find nearest neighbors at each layer\n",
        "        self.centers = {} # mean of training data representation per layer (that needs to be substracted before NearestNeighbor)\n",
        "\n",
        "        print(\"## Constructing the NearestNeighbor tables\")\n",
        "\n",
        "        for layer in self.layers:\n",
        "            print(\"Constructing table for {}\".format(layer))\n",
        "\n",
        "            # Normalize all the lenghts, since we care about the cosine similarity\n",
        "            self.train_activations_lsh[layer] /= np.linalg.norm(self.train_activations_lsh[layer], axis=1).reshape(-1, 1)\n",
        "\n",
        "            # Center the dataset and the queries: this improves the performance of LSH quite a bit\n",
        "            center = np.mean(self.train_activations_lsh[layer], axis=0)\n",
        "            self.train_activations_lsh[layer] -= center\n",
        "            self.centers[layer] = center\n",
        "\n",
        "            # Constructing nearest neighbor table\n",
        "            self.query_objects[layer] = NearestNeighbor(\n",
        "                backend=self.backend,\n",
        "                dimension=self.train_activations_lsh[layer].shape[1],\n",
        "                number_bits=self.number_bits,\n",
        "                neighbors=self.neighbors,\n",
        "                nb_tables=self.nb_tables,\n",
        "            )\n",
        "\n",
        "            self.query_objects[layer].add(self.train_activations_lsh[layer])\n",
        "\n",
        "        print(\"done!\")\n",
        "        print()\n",
        "\n",
        "\n",
        "    def calibrate(self, calibloader):\n",
        "        \"\"\"\n",
        "        Runs the DkNN on holdout data to calibrate the credibility metric\n",
        "        :param calibloader: data loader for the calibration loader\n",
        "        \"\"\"\n",
        "        print('---------- DkNN calibrate')\n",
        "        print()\n",
        "\n",
        "        # Compute calibration data activations\n",
        "        self.nb_cali = len(calibloader.dataset)\n",
        "        activations = get_activations(calibloader, self.model, self.layers)\n",
        "        self.cali_activations = activations['activations']\n",
        "        self.cali_labels = activations['targets']\n",
        "\n",
        "        print(\"## Starting calibration of DkNN\")\n",
        "\n",
        "        cali_knns_ind, cali_knns_labels = self.find_train_knns(self.cali_activations)\n",
        "        assert all([v.shape == (self.nb_cali, self.neighbors) for v in cali_knns_ind.values()])\n",
        "        assert all([v.shape == (self.nb_cali, self.neighbors) for v in cali_knns_labels.values()])\n",
        "\n",
        "        cali_knns_not_in_class = self.nonconformity(cali_knns_labels)\n",
        "        cali_knns_not_in_l = np.zeros(self.nb_cali, dtype=np.int32)\n",
        "\n",
        "        for i in range(self.nb_cali):\n",
        "            cali_knns_not_in_l[i] = cali_knns_not_in_class[i, self.cali_labels[i]]\n",
        "\n",
        "        cali_knns_not_in_l_sorted = np.sort(cali_knns_not_in_l)\n",
        "        self.cali_nonconformity = np.trim_zeros(cali_knns_not_in_l_sorted, trim='f')\n",
        "        self.nb_cali = self.cali_nonconformity.shape[0]\n",
        "        self.calibrated = True\n",
        "\n",
        "        print(\"DkNN calibration complete\")\n",
        "\n",
        "    def find_train_knns(self, data_activations):\n",
        "        \"\"\"\n",
        "        Given a data_activation dictionary that contains a np array with activations for each layer,\n",
        "        find the knns in the training data\n",
        "        \"\"\"\n",
        "        knns_ind = {}\n",
        "        knns_labels = {}\n",
        "\n",
        "        for layer in self.layers:\n",
        "            # Pre-process representations of data to normalize and remove training data mean\n",
        "            data_activations_layer = copy.copy(data_activations[layer])\n",
        "            nb_data = data_activations_layer.shape[0]\n",
        "            data_activations_layer /= np.linalg.norm(data_activations_layer, axis=1).reshape(-1, 1)\n",
        "            data_activations_layer -= self.centers[layer]\n",
        "\n",
        "            # Use FALCONN to find indices of nearest neighbors in training data\n",
        "            knns_ind[layer] = np.zeros((data_activations_layer.shape[0], self.neighbors), dtype=np.int32)\n",
        "            knn_errors = 0\n",
        "\n",
        "            knn_missing_indices = self.query_objects[layer].find_knns(data_activations_layer, knns_ind[layer])\n",
        "            knn_errors += knn_missing_indices.flatten().sum()\n",
        "\n",
        "            # Find labels of neighbors found in the training data\n",
        "            knns_labels[layer] = np.zeros((nb_data, self.neighbors), dtype=np.int32)\n",
        "\n",
        "            knns_labels[layer].reshape(-1)[\n",
        "                np.logical_not(knn_missing_indices.flatten())\n",
        "            ] = self.train_labels[\n",
        "                knns_ind[layer].reshape(-1)[np.logical_not(knn_missing_indices.flatten())]                    \n",
        "            ]\n",
        "\n",
        "        return knns_ind, knns_labels\n",
        "\n",
        "    def nonconformity(self, knns_labels):\n",
        "        \"\"\"\n",
        "        Given an dictionary of nb_data x nb_classes dimension, compute the nonconformity of\n",
        "        each candidate label for each data point: i.e. the number of knns whose label is\n",
        "        different from the candidate label\n",
        "        \"\"\"\n",
        "        nb_data = knns_labels[list(self.layers.keys())[0]].shape[0]\n",
        "        knns_not_in_class = np.zeros((nb_data, self.nb_classes), dtype=np.int32)\n",
        "\n",
        "        for i in range(nb_data):\n",
        "            # Compute number of nearest neighbors per class\n",
        "            knns_in_class = np.zeros((len(self.layers), self.nb_classes), dtype=np.int32)\n",
        "\n",
        "            for layer_id, layer in enumerate(self.layers):\n",
        "                knns_in_class[layer_id, :] = np.bincount(knns_labels[layer][i], minlength=self.nb_classes)\n",
        "\n",
        "            # Compute number of knns in other class than class_id\n",
        "            for class_id in range(self.nb_classes):\n",
        "                knns_not_in_class[i, class_id] = np.sum(knns_in_class) - np.sum(knns_in_class[:, class_id])\n",
        "\n",
        "        return knns_not_in_class\n",
        "\n",
        "    def fprop(self, testloader):\n",
        "        \"\"\"\n",
        "        Performs a forward pass through the DkNN on an numpy array of data\n",
        "        \"\"\"\n",
        "        print('---------- DkNN predict')\n",
        "        print()\n",
        "\n",
        "        if not self.calibrated:\n",
        "            raise ValueError(\"DkNN needs to be calibrated by calling DkNNModel.calibrate method once before inferring\")\n",
        "\n",
        "        # Compute test data activations\n",
        "        activations = get_activations(testloader, self.model, self.layers)\n",
        "        data_activations = activations['activations']\n",
        "        _, knns_labels = self.find_train_knns(data_activations)\n",
        "\n",
        "        # Calculate nonconformity\n",
        "        knns_not_in_class = self.nonconformity(knns_labels)\n",
        "        print('Nonconformity calculated')\n",
        "\n",
        "        # Create predictions, confidence and credibility\n",
        "        # _, _,creds = self.preds_conf_cred(knns_not_in_class)\n",
        "        preds_knn, confs,creds = self.preds_conf_cred(knns_not_in_class)\n",
        "        print('Predictions created')\n",
        "\n",
        "        return creds, activations['targets'],preds_knn,confs\n",
        "\n",
        "    def preds_conf_cred(self, knns_not_in_class):\n",
        "        \"\"\"\n",
        "        Given an array of nb_data x nb_classes dimensions, use conformal prediction to compute\n",
        "        the DkNN's prediction, confidence and credibility\n",
        "        \"\"\"\n",
        "        nb_data = knns_not_in_class.shape[0]\n",
        "        preds_knn = np.zeros(nb_data, dtype=np.int32)\n",
        "        confs = np.zeros((nb_data, self.nb_classes), dtype=np.float32)\n",
        "        creds = np.zeros((nb_data, self.nb_classes), dtype=np.float32)\n",
        "\n",
        "        for i in range(nb_data):\n",
        "            # p-value of test input for each class\n",
        "            p_value = np.zeros(self.nb_classes, dtype=np.float32)\n",
        "\n",
        "            for class_id in range(self.nb_classes):\n",
        "                # p-value of (test point, candidate label)\n",
        "                p_value[class_id] = (float(self.nb_cali) - bisect_left(self.cali_nonconformity, knns_not_in_class[i, class_id])) / float(self.nb_cali)\n",
        "\n",
        "            preds_knn[i] = np.argmax(p_value)\n",
        "            confs[i, preds_knn[i]] = 1. - np.sort(p_value)[-2]\n",
        "            creds[i, preds_knn[i]] = p_value[preds_knn[i]]\n",
        "\n",
        "        return preds_knn, confs, creds\n",
        "\n",
        "\n",
        "def plot_reliability_diagram(confidence, labels):\n",
        "    \"\"\"\n",
        "    Takes in confidence values (e.g. output of softmax or DkNN confidences) for\n",
        "    predictions and correct labels for the data, plots a reliability diagram\n",
        "    :param confidence: nb_samples x nb_classes with confidence scores\n",
        "    :param labels: targets\n",
        "    \"\"\"\n",
        "    assert len(confidence.shape) == 2\n",
        "    assert len(labels.shape) == 1\n",
        "    assert confidence.shape[0] == labels.shape[0]\n",
        "\n",
        "    if confidence.max() <= 1.:\n",
        "        # confidence array is output of softmax\n",
        "        bins_start = [b / 10. for b in range(0, 10)]\n",
        "        bins_end = [b / 10. for b in range(1, 11)]\n",
        "        bins_center = [(b + .5) / 10. for b in range(0, 10)]\n",
        "        preds_conf = np.max(confidence, axis=1)\n",
        "        preds_l = np.argmax(confidence, axis=1)\n",
        "    else:\n",
        "        raise ValueError('Confidence values go above 1')\n",
        "\n",
        "    print(preds_conf.shape, preds_l.shape)\n",
        "\n",
        "    # Create var for reliability diagram (Will contain mean accuracies for each bin)\n",
        "    reliability_diag = []\n",
        "    num_points = []  # keeps the number of points in each bar\n",
        "\n",
        "    # Find average accuracy per confidence bin\n",
        "    for bin_start, bin_end in zip(bins_start, bins_end):\n",
        "        above = preds_conf >= bin_start\n",
        "\n",
        "        if bin_end == 1.:\n",
        "            below = preds_conf <= bin_end\n",
        "        else:\n",
        "            below = preds_conf < bin_end\n",
        "\n",
        "        mask = np.multiply(above, below)\n",
        "        num_points.append(np.sum(mask))\n",
        "\n",
        "        bin_mean_acc = max(0, np.mean(preds_l[mask] == labels[mask]))\n",
        "        reliability_diag.append(bin_mean_acc)\n",
        "\n",
        "    # Plot diagram\n",
        "    assert len(reliability_diag) == len(bins_center)\n",
        "    #print(reliability_diag)\n",
        "    #print(bins_center)\n",
        "    #print(num_points)\n",
        "\n",
        "    fig, ax1 = plt.subplots()\n",
        "    _ = ax1.bar(bins_center, reliability_diag, width=.1, alpha=0.8, edgecolor = \"black\")\n",
        "    plt.xlim([0, 1.])\n",
        "    ax1.set_ylim([0, 1.])\n",
        "\n",
        "    ax2 = ax1.twinx()\n",
        "\n",
        "    #print(sum(num_points))\n",
        "\n",
        "    ax2.plot(bins_center, num_points, color='r', linestyle='-', linewidth=7.0)\n",
        "    ax2.set_ylabel('Number of points in the data', fontsize=16, color='r')\n",
        "\n",
        "    if len(np.argwhere(confidence[0] != 0.)) == 1:\n",
        "        # This is a DkNN diagram\n",
        "        ax1.set_xlabel('Prediction Credibility', fontsize=16)\n",
        "    else:\n",
        "        # This is a softmax diagram\n",
        "        ax1.set_xlabel('Prediction Confidence', fontsize=16)\n",
        "\n",
        "    ax1.set_ylabel('Prediction Accuracy', fontsize=16)\n",
        "    ax1.tick_params(axis='both', labelsize=14)\n",
        "    ax2.tick_params(axis='both', labelsize=14, colors='r')\n",
        "    fig.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOXkJ-EB5rGU"
      },
      "source": [
        "Let's create a dataloader for training data that should be used to initialize the DkNN (shuffle must be false!). Then, initialize the DkNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX8Op544r4Wu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c26b4ca-f447-4c01-f53e-76a0c98b9062"
      },
      "source": [
        "# Create training data loader for DkNN\n",
        "trainloader_dknn = torch.utils.data.DataLoader(                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
        "    trainset, batch_size=batch_size_train, shuffle=False, num_workers=3\n",
        ")\n",
        "\n",
        "# Initialize DkNN\n",
        "nb_classes_mnist = 10\n",
        "dknn = DkNN(model, nb_classes_mnist, neighbors, layers, trainloader_dknn, NearestNeighbor.BACKEND.FALCONN)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------- DkNN init\n",
            "\n",
            "## Fetching Activations from Layer relu1\n",
            "Processing Batch 0\n",
            "Processing Batch 1\n",
            "Processing Batch 2\n",
            "Processing Batch 3\n",
            "Processing Batch 4\n",
            "Processing Batch 5\n",
            "Processing Batch 6\n",
            "Processing Batch 7\n",
            "Processing Batch 8\n",
            "Processing Batch 9\n",
            "Processing Batch 10\n",
            "Processing Batch 11\n",
            "Processing Batch 12\n",
            "Processing Batch 13\n",
            "Processing Batch 14\n",
            "Processing Batch 15\n",
            "Processing Batch 16\n",
            "Processing Batch 17\n",
            "Processing Batch 18\n",
            "Processing Batch 19\n",
            "Processing Batch 20\n",
            "done!\n",
            "\n",
            "## Fetching Activations from Layer relu2\n",
            "Processing Batch 0\n",
            "Processing Batch 1\n",
            "Processing Batch 2\n",
            "Processing Batch 3\n",
            "Processing Batch 4\n",
            "Processing Batch 5\n",
            "Processing Batch 6\n",
            "Processing Batch 7\n",
            "Processing Batch 8\n",
            "Processing Batch 9\n",
            "Processing Batch 10\n",
            "Processing Batch 11\n",
            "Processing Batch 12\n",
            "Processing Batch 13\n",
            "Processing Batch 14\n",
            "Processing Batch 15\n",
            "Processing Batch 16\n",
            "Processing Batch 17\n",
            "Processing Batch 18\n",
            "Processing Batch 19\n",
            "Processing Batch 20\n",
            "done!\n",
            "\n",
            "## Fetching Activations from Layer relu3\n",
            "Processing Batch 0\n",
            "Processing Batch 1\n",
            "Processing Batch 2\n",
            "Processing Batch 3\n",
            "Processing Batch 4\n",
            "Processing Batch 5\n",
            "Processing Batch 6\n",
            "Processing Batch 7\n",
            "Processing Batch 8\n",
            "Processing Batch 9\n",
            "Processing Batch 10\n",
            "Processing Batch 11\n",
            "Processing Batch 12\n",
            "Processing Batch 13\n",
            "Processing Batch 14\n",
            "Processing Batch 15\n",
            "Processing Batch 16\n",
            "Processing Batch 17\n",
            "Processing Batch 18\n",
            "Processing Batch 19\n",
            "Processing Batch 20\n",
            "done!\n",
            "\n",
            "## Fetching Activations from Layer fc\n",
            "Processing Batch 0\n",
            "Processing Batch 1\n",
            "Processing Batch 2\n",
            "Processing Batch 3\n",
            "Processing Batch 4\n",
            "Processing Batch 5\n",
            "Processing Batch 6\n",
            "Processing Batch 7\n",
            "Processing Batch 8\n",
            "Processing Batch 9\n",
            "Processing Batch 10\n",
            "Processing Batch 11\n",
            "Processing Batch 12\n",
            "Processing Batch 13\n",
            "Processing Batch 14\n",
            "Processing Batch 15\n",
            "Processing Batch 16\n",
            "Processing Batch 17\n",
            "Processing Batch 18\n",
            "Processing Batch 19\n",
            "Processing Batch 20\n",
            "done!\n",
            "\n",
            "## Constructing the NearestNeighbor tables\n",
            "Constructing table for relu1\n",
            "Constructing table for relu2\n",
            "Constructing table for relu3\n",
            "Constructing table for fc\n",
            "done!\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pz04V-f_6IFi"
      },
      "source": [
        "Then, calibrate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4lBatc9sX7V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e12bd05f-9e2f-4df0-aaa8-a41fc1dcc35f"
      },
      "source": [
        "dknn.calibrate(calibloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------- DkNN calibrate\n",
            "\n",
            "## Fetching Activations from Layer relu1\n",
            "Processing Batch 0\n",
            "Processing Batch 1\n",
            "Processing Batch 2\n",
            "Processing Batch 3\n",
            "Processing Batch 4\n",
            "Processing Batch 5\n",
            "Processing Batch 6\n",
            "Processing Batch 7\n",
            "Processing Batch 8\n",
            "Processing Batch 9\n",
            "done!\n",
            "\n",
            "## Fetching Activations from Layer relu2\n",
            "Processing Batch 0\n",
            "Processing Batch 1\n",
            "Processing Batch 2\n",
            "Processing Batch 3\n",
            "Processing Batch 4\n",
            "Processing Batch 5\n",
            "Processing Batch 6\n",
            "Processing Batch 7\n",
            "Processing Batch 8\n",
            "Processing Batch 9\n",
            "done!\n",
            "\n",
            "## Fetching Activations from Layer relu3\n",
            "Processing Batch 0\n",
            "Processing Batch 1\n",
            "Processing Batch 2\n",
            "Processing Batch 3\n",
            "Processing Batch 4\n",
            "Processing Batch 5\n",
            "Processing Batch 6\n",
            "Processing Batch 7\n",
            "Processing Batch 8\n",
            "Processing Batch 9\n",
            "done!\n",
            "\n",
            "## Fetching Activations from Layer fc\n",
            "Processing Batch 0\n",
            "Processing Batch 1\n",
            "Processing Batch 2\n",
            "Processing Batch 3\n",
            "Processing Batch 4\n",
            "Processing Batch 5\n",
            "Processing Batch 6\n",
            "Processing Batch 7\n",
            "Processing Batch 8\n",
            "Processing Batch 9\n",
            "done!\n",
            "\n",
            "## Starting calibration of DkNN\n",
            "DkNN calibration complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ScK3G87tBo3"
      },
      "source": [
        "Run DkNN on train set \n",
        "\n",
        "Collect misclassified training points"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUECY5s5newa"
      },
      "source": [
        "White Box Attacks\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7N89OO1bfm2"
      },
      "source": [
        "def ifgsm(\n",
        "    model,\n",
        "    X,\n",
        "    y,\n",
        "    niters=10,\n",
        "    epsilon=0.03,\n",
        "    visualize=False,\n",
        "    learning_rate=0.005,\n",
        "    display=4,\n",
        "    defense_model=False,\n",
        "    setting=\"regular\",\n",
        "    dataset=\"cifar10\",\n",
        "    use_Inc_model = False,\n",
        "):\n",
        "    \"\"\"Perform ifgsm attack with respect to model on images X with labels y\n",
        "    Args:\n",
        "        model: torch model with respect to which attacks will be computed\n",
        "        X: batch of torch images\n",
        "        y: labels corresponding to the batch of images\n",
        "        niters: number of iterations of ifgsm to perform\n",
        "        epsilon: Linf norm of resulting perturbation; scale of images is -1..1\n",
        "        visualize: whether you want to visualize the perturbations or not\n",
        "        learning_rate: learning rate of ifgsm\n",
        "        display: number of images to display in visualization\n",
        "        defense_model: set to true if you are using a defended model,\n",
        "        e.g. ResNet18Defended, instead of the usual ResNet18\n",
        "        setting: 'regular' is usual ifgsm, 'll' is least-likely ifgsm, and\n",
        "        'nonleaking' is non-label-leaking ifgsm\n",
        "        dataset: dataset the images are from, 'cifar10' | 'imagenet'\n",
        "    Returns:\n",
        "        The batch of adversarial examples corresponding to the original images\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    out = None\n",
        "    if defense_model:\n",
        "        out = model(X)[0]\n",
        "    else:\n",
        "        out = model(X)\n",
        "    y_ll = out.min(1)[1]  # least likely model output\n",
        "    y_ml = out.max(1)[1]  # model label\n",
        "\n",
        "    X_pert = X.clone()\n",
        "    X_pert.requires_grad = True\n",
        "    for i in range(niters):\n",
        "        output_perturbed = None\n",
        "        if defense_model:\n",
        "            output_perturbed = model(X_pert)[0]\n",
        "        else:\n",
        "            output_perturbed = model(X_pert)\n",
        "\n",
        "        y_used = y\n",
        "        ll_factor = 1\n",
        "        if setting == \"ll\":\n",
        "            y_used = y_ll\n",
        "            ll_factor = -1\n",
        "        elif setting == \"noleaking\":\n",
        "            y_used = y_ml\n",
        "\n",
        "        loss = nn.CrossEntropyLoss()(output_perturbed, y_used)\n",
        "        loss.backward()\n",
        "        pert = ll_factor * learning_rate * X_pert.grad.detach().sign()\n",
        "\n",
        "        # perform visualization\n",
        "        if visualize is True and i == niters - 1:\n",
        "            np_image = sow_images(X[:display].detach())\n",
        "            np_delta = sow_images(pert[:display].detach())\n",
        "            np_recons = sow_images(\n",
        "                (X_pert.detach() + pert.detach()).clamp(-1, 1)[:display]\n",
        "            )\n",
        "\n",
        "            fig = plt.figure(figsize=(8, 8))\n",
        "            fig.add_subplot(3, 1, 1)\n",
        "            plt.axis(\"off\")\n",
        "            plt.imshow(np_recons)\n",
        "            fig.add_subplot(3, 1, 2)\n",
        "            plt.axis(\"off\")\n",
        "            plt.imshow(np_image)\n",
        "            fig.add_subplot(3, 1, 3)\n",
        "            plt.axis(\"off\")\n",
        "            plt.imshow(np_delta)\n",
        "            plt.show()\n",
        "        # end visualization\n",
        "\n",
        "        # add perturbation\n",
        "        X_pert = X_pert.detach() + pert\n",
        "        X_pert.requires_grad = True\n",
        "\n",
        "        # make sure we don't modify the original image beyond epsilon and clamp\n",
        "        X_pert = renormalization(X, X_pert, epsilon, dataset=dataset, use_Inc_model=use_Inc_model)\n",
        "        X_pert.requires_grad = True\n",
        "\n",
        "    return X_pert\n",
        "\n",
        "\n",
        "def fgsm(model, X, y, epsilon=0.01, **args):\n",
        "    \"\"\"Perform cifar 10 fgsm attack with respect to model on images X with labels y\n",
        "    Args:\n",
        "        model: torch model with respect to which attacks will be computed\n",
        "        X: batch of torch images\n",
        "        y: labels corresponding to the batch of images\n",
        "        epsilon: Linf norm of resulting perturbation; scale of images is -1..1\n",
        "    Returns:\n",
        "        The batch of adversarial examples corresponding to the original images\n",
        "    \"\"\"\n",
        "    if dataset != \"cifar10\":\n",
        "        raise \"fgsm as now does not support \" + dataset\n",
        "\n",
        "    X_pert = X.clone()\n",
        "    X_pert.requires_grad = True\n",
        "    output_perturbed = model(X_pert)\n",
        "    loss = nn.CrossEntropyLoss()(output_perturbed, y)\n",
        "    loss.backward()\n",
        "\n",
        "    pert = epsilon * X_pert.grad.detach().sign()\n",
        "    X_pert = X_pert.detach() + pert\n",
        "    X_pert = X_pert.detach().clamp(X.min(), X.max())\n",
        "    return X_pert\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJYdEORQoLzL"
      },
      "source": [
        "def ILA(\n",
        "    model,\n",
        "    X,\n",
        "    X_attack,\n",
        "    y,\n",
        "    feature_layer,\n",
        "    niters=10,\n",
        "    epsilon=0.01,\n",
        "    coeff=1.0,\n",
        "    learning_rate=1,\n",
        "    dataset=\"cifar10\",\n",
        "    use_Inc_model = False,\n",
        "    with_projection=True,\n",
        "):\n",
        "    \"\"\"Perform ILA attack with respect to model on images X with labels y\n",
        "    Args:\n",
        "        with_projection: boolean, specifies whether projection should happen\n",
        "        in the attack\n",
        "        model: torch model with respect to which attacks will be computed\n",
        "        X: batch of torch images\n",
        "        X_attack: starting adversarial examples of ILA that will be modified\n",
        "        to become more transferable\n",
        "        y: labels corresponding to the batch of images\n",
        "        feature_layer: layer of model to project on in ILA attack\n",
        "        niters: number of iterations of the attack to perform\n",
        "        epsilon: Linf norm of resulting perturbation; scale of images is -1..1\n",
        "        coeff: coefficient of magnitude loss in ILA attack\n",
        "        visualize: whether you want to visualize the perturbations or not\n",
        "        learning_rate: learning rate of the attack\n",
        "        dataset: dataset the images are from, 'cifar10' | 'imagenet'\n",
        "    Returns:\n",
        "        The batch of modified adversarial examples, examples have been\n",
        "        augmented from X_attack to become more transferable\n",
        "    \"\"\"\n",
        "    X = X.detach()\n",
        "    X_pert = torch.zeros(X.size()).cuda()\n",
        "    X_pert.copy_(X).detach()\n",
        "    X_pert.requires_grad = True\n",
        "\n",
        "    def get_mid_output(m, i, o):\n",
        "        global mid_output\n",
        "        mid_output = o\n",
        "\n",
        "    h = feature_layer.register_forward_hook(get_mid_output)\n",
        "\n",
        "    out = model(X)\n",
        "    mid_original = torch.zeros(mid_output.size()).cuda()\n",
        "    mid_original.copy_(mid_output)\n",
        "\n",
        "    out = model(X_attack)\n",
        "    mid_attack_original = torch.zeros(mid_output.size()).cuda()\n",
        "    mid_attack_original.copy_(mid_output)\n",
        "\n",
        "    for _ in range(niters):\n",
        "        output_perturbed = model(X_pert)\n",
        "\n",
        "        # generate adversarial example by max middle layer pertubation\n",
        "        # in the direction of increasing loss\n",
        "        if with_projection:\n",
        "            loss = Proj_Loss()(\n",
        "                mid_attack_original.detach(), mid_output, mid_original.detach(), coeff\n",
        "            )\n",
        "        else:\n",
        "            loss = Mid_layer_target_Loss()(\n",
        "                mid_attack_original.detach(), mid_output, mid_original.detach(), coeff\n",
        "            )\n",
        "\n",
        "        loss.backward()\n",
        "        pert = learning_rate * X_pert.grad.detach().sign()\n",
        "\n",
        "        # minimize loss\n",
        "        X_pert = X_pert.detach() + pert\n",
        "        X_pert.requires_grad = True\n",
        "\n",
        "        # make sure we don't modify the original image beyond epsilon\n",
        "        X_pert = renormalization(X, X_pert, epsilon, dataset=dataset, use_Inc_model=use_Inc_model)\n",
        "        X_pert.requires_grad = True\n",
        "\n",
        "    h.remove()\n",
        "    return X_pert\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "qymSzCCYnhA2",
        "outputId": "deaeedc7-278f-4eb7-a280-f617bf6cddec"
      },
      "source": [
        "img_ifgsm = ifgsm(model, img, lbl, niters=opt.niters_baseline, dataset='clean_x.npy')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-6ba2d8e27e03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg_ifgsm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mifgsm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mniters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mniters_baseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'clean_x.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gkk6nG9koEeV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}